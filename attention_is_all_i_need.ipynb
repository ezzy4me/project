{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attention is all i need.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMKa2Kl0myTfpPpCBtjea5r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ezzy4me/project/blob/main/attention_is_all_i_need.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer implementing"
      ],
      "metadata": {
        "id": "1CwR1xKxsutw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "library"
      ],
      "metadata": {
        "id": "RM8iwlHiBusD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math, copy, time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.style.use('dark_background')"
      ],
      "metadata": {
        "id": "A5gM-4Itst4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-WME5ysHB7mW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Embedding"
      ],
      "metadata": {
        "id": "WYZpOq4DB7OX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedding(nn.Module):\n",
        "    \"\"\"Custom Embedding Layer\"\"\"\n",
        "    def __init__(self, vocab_len, d_model, padding_idx=1):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embedding = nn.Embedding(vocab_len, d_model, padding_idx=padding_idx) #nn.Embedding(num_embeddings, embedding_dim)\n",
        "    def forward(self, x):\n",
        "        # In the embedding layers, authors multiply those weights by `sqrt(d_model)`\n",
        "        return self.embedding(x) * np.sqrt(self.d_model)"
      ],
      "metadata": {
        "id": "XLa9SnizBy4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "position = torch.arange(0, 5).unsqueeze(1)\n",
        "print(position.size())\n",
        "#torch.arange(0, 20, 2) \n",
        "\n",
        "#pe = torch.zeros(10, 20)\n",
        "#pe.unsqueeze(0).size()\n",
        "\n",
        "div_term = torch.exp(torch.arange(0, 20, 2))\n",
        "print(div_term.size())\n",
        "\n",
        "pe = torch.sin(position * div_term)\n",
        "print(pe.size())\n",
        "\n",
        "pe.size(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXKN8vnm3uR8",
        "outputId": "11645fb2-f6a8-42f9-d770-316cdd7ac17b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 1])\n",
            "torch.Size([10])\n",
            "torch.Size([5, 10])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"Position Encoding function\"\"\"\n",
        "    def __init__(self, d_model, dropout, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        \n",
        "        # Compute the positional encodings once in log space.\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1) #size[max_len, 1]\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * \n",
        "                             -(math.log(10000.0) / d_model)) #size[d_model/2]\n",
        "        pe[:, 0::2] = torch.sin(position * div_term) #2i\n",
        "        pe[:, 1::2] = torch.cos(position * div_term) #2i+1\n",
        "        pe = pe.unsqueeze(0) #size[1, max_len, d_model]\n",
        "\n",
        "        #Adds a buffer to the module.\n",
        "        #register a buffer that should not to be considered a model parameter. \n",
        "        #optimizer doesn't update it. but value is available\n",
        "        self.register_buffer('pe', pe) #state_dict #register_buffer(name, tensor, persistent=True)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        pe_val = self.pe[:, :x.size(1)]\n",
        "        \n",
        "        #freezing the part of the model as no changes happen to its parameters\n",
        "        pe_val.requires_grad = False\n",
        "        \n",
        "        x = x + pe_val\n",
        "        # x = x + Variable(self.pe[:, :x.size(1)], requires_grad=False)\n",
        "\n",
        "        # page 7\n",
        "        # In addition, we apply dropout to the sums of the embeddings and the\n",
        "        # positional encodings in both the encoder and decoder stacks.\n",
        "        # For the base model, we use a rate of Pdrop=0.1.\n",
        "        return self.dropout(x)\n",
        "        "
      ],
      "metadata": {
        "id": "FSHO7b_E3K5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lKo06OzTYbW-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "final stage"
      ],
      "metadata": {
        "id": "xdosLoT8BzRI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WDkkwzP4qDfs"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class TransformerModel(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self._is_generation_fast = False #????\n",
        "        self.encoder = encoder \n",
        "        self.decoder = decoder\n",
        "        \n",
        "    def forward(self, src_tokens, src_lengths, prev_output_tokens):\n",
        "        encoder_out, padding_mask = self.encoder(src_tokens, src_lengths) #\n",
        "        decoder_out = self.decoder(prev_output_tokens, encoder_out, padding_mask) #\n",
        "        return decoder_out #final output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "F2lkK-zEs1Q8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}